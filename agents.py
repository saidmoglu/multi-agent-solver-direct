from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Literal, Sequence

from openai import OpenAI
from pydantic import BaseModel

from representation_utils import (
    GRID,
    generate_grid_diff,
    grid_to_base64_png,
    grid_to_text,
)
from state import SolverState, build_user_content_samples

InstructionConfidence = Literal["low", "medium", "high"]


@dataclass(slots=True)
class InstructionAgentResult:
    instruction: str
    rationale: str
    confidence: InstructionConfidence
    usage: dict[str, int]


@dataclass(slots=True)
class GeneratorGridResult:
    grid: GRID | None
    grid_text: str | None
    grid_image_b64: str | None


@dataclass(slots=True)
class GeneratorAgentResult:
    status_and_findings: str
    train_outputs: list[GeneratorGridResult]
    test_outputs: list[GeneratorGridResult]
    usage: dict[str, int]


INSTRUCTION_AGENT_SYSTEM_PROMPT = """
You are an expert ARC reasoning assistant.
You are given the current state of an ARC puzzle solving attempt, including:
- Train and test samples with inputs, expected outputs, and any current partial outputs generated by the generator agent.
- The history of instructions issued so far.
- The status and findings reported by the generator agent for the latest instruction.
Your task is to think about the transformation and identify the entire sequence of transformation. Then, as your response, produce one minimal, precise next instruction step for the generator agent to apply.
These instruction steps must:

- Be based on your thinking process about the transformation pattern observed in the training samples.
- Be incremental, building upon previous instructions.
- Focus on a single, clear transformation action or identification step.
- Be actionable by the generator agent to update the outputs.
- Max number of steps allowed is {{max_steps}} including any potential corrective instructions you may give, so plan accordingly.
- Reflect your confidence level in the instruction you are providing (low, medium, high).
- Apply consistently to ALL training examples (the same rule works for every inputâ†’output pair)
- Be intuitive and easy to understand
- Be as specific as possible to avoid ambiguity

The eventual goal is to solve the test samples correctly by iteratively applying these instructions. It is acceptable that the instructions have specific details tailored to the test samples.
If the generator agent doesn't seem to be on the correct path, provide corrective instructions.

A few examples of good instructions:
example 1:
- Identify the largest connected component in the input grid
- Recolor it to color 3, and mirror it horizontally.
example 2:
- Crop the input grid to the bounding box of non-background pixels, 
- then rotate it 90 degrees clockwise and place it in the top-left corner of the output grid.
example 3:
- Identify all objects in the input grid. Ignore the bracket objects that are size ... and shape .... 
- For the remaining objects, recolor them to color ... and translate them according to this rule: ...
example 4:
- Identify the smaller area created by a color 5 border. This is the guide area.
- Inside this area, color mappings are given as a guide. Objects with 1 hole in it are colored with a certain color, objects with 2 holes another color, etc. Identify these mappings.
- The objects in the larger area are then recolored according to the mapping.

The actual instructions you write must follow the same principles as these examples, but be tailored to the specific transformation pattern in the training data provided.

Never execute the transformation yourself.
Reference previous instructions, generator status and findings, and diffs between expected and actual outputs.
Allow revisions to previous instructions when necessary.

"""

GENERATOR_AGENT_SYSTEM_PROMPT = """
You transform ARC grids strictly following the provided instructions.
Update outputs for all train and test samples.
You must always output updated grids. If the instruction does not require any changes yet, you must still output the existing grids (input grids or the latest grids) unchanged.
Always re-emit existing outputs unchanged when no update is required.
Your previous status and findings message is below. Return a new, complete status and findings message that combines the previous one with your latest observations and status.
For example, if an instruction says "Identify the largest connected component" then your status and findings should describe precisely what you found regarding connected components in the inputs.
For example, if an instruction says "Recolor all objects of color 3 to color 5", your status and findings should describe how many objects of color 3 you found and recolored in each sample. You must also update the output grids accordingly.
"""


class InstructionAgent:
    """LLM-backed instruction planner producing single incremental steps."""

    def __init__(self, client: OpenAI, *, system_prompt: str | None = None) -> None:
        self.client = client
        self.system_prompt = system_prompt or INSTRUCTION_AGENT_SYSTEM_PROMPT

    def __call__(self, state: SolverState) -> InstructionAgentResult:
        input_payload = self._build_input(state)
        response = self.client.responses.parse(
            model="gpt-5",
            input=input_payload,
            reasoning={"effort": state.config.reasoning_effort()},
            service_tier="priority",
            text_format=InstructionSchema,
        )
        data = response.output_parsed
        usage = _extract_usage(response)
        instruction = data.instruction.strip()
        rationale = data.rationale.strip()
        confidence = data.confidence.strip() or "medium"
        if not instruction:
            raise ValueError("Instruction agent returned empty instruction.")
        return InstructionAgentResult(
            instruction=instruction,
            rationale=rationale,
            confidence=confidence,  # type: ignore[arg-type]
            usage=usage,
        )

    def _build_input(self, state: SolverState) -> list[dict[str, Any]]:
        parts: list[dict[str, Any]] = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "input_text",
                        "text": self.system_prompt.format(
                            max_steps=state.config.max_steps,
                        ),
                    }
                ],
            }
        ]
        user_parts: list[dict[str, Any]] = []

        if state.instructions:
            instruction_lines = "\n".join(
                f"{idx + 1}. {text}" for idx, text in enumerate(state.instructions)
            )
            user_parts.append({"type": "input_text", "text": "Instructions so far:"})
            user_parts.append({"type": "input_text", "text": instruction_lines})
        else:
            user_parts.append(
                {"type": "input_text", "text": "Instructions so far: (none)"}
            )
        user_parts.append(
            {
                "type": "input_text",
                "text": f"Generator status and findings so far: {state.generator_status_and_findings or 'N/A'}",
            }
        )
        train_entries = []
        for index, (train_input, train_expected) in enumerate(
            zip(state.samples.train_inputs, state.samples.train_outputs, strict=True)
        ):
            diff_text = None
            partial = state.train_partial_outputs[index]
            if partial is not None:
                diff_text = generate_grid_diff(train_expected, partial)
            train_entries.append(
                {
                    "label": f"Train {index} INPUT",
                    "grid": train_input,
                }
            )
            if partial is not None:
                train_entries.append(
                    {
                        "label": f"Train {index} CURRENT OUTPUT FROM GENERATOR",
                        "grid": partial,
                        "diff": diff_text,
                    }
                )
            train_entries.append(
                {
                    "label": f"Train {index} EXPECTED OUTPUT",
                    "grid": train_expected,
                }
            )

        test_entries = [
            {"label": f"Test {idx} INPUT", "grid": grid}
            for idx, grid in enumerate(state.samples.test_inputs)
        ]

        if train_entries:
            user_parts.extend(
                build_user_content_samples(
                    "Train Sample",
                    train_entries,
                    use_images=state.config.should_use_images(),
                )
            )
        if test_entries:
            user_parts.extend(
                build_user_content_samples(
                    "Test Sample",
                    test_entries,
                    use_images=state.config.should_use_images(),
                )
            )

        parts.append({"role": "user", "content": user_parts})
        return parts


class GeneratorAgent:
    """LLM-backed agent applying instructions to produce partial outputs."""

    def __init__(self, client: OpenAI, *, system_prompt: str | None = None) -> None:
        self.client = client
        self.system_prompt = system_prompt or GENERATOR_AGENT_SYSTEM_PROMPT

    def __call__(self, state: SolverState, instruction: str) -> GeneratorAgentResult:
        input_payload = self._build_input(state, instruction)
        response = self.client.responses.parse(
            model="gpt-5",
            input=input_payload,
            reasoning={"effort": state.config.reasoning_effort()},
            service_tier="priority",
            text_format=GeneratorSchema,
        )
        data = response.output_parsed
        usage = _extract_usage(response)
        status_and_findings = data.status_and_findings.strip()
        if not status_and_findings:
            raise ValueError("Generator agent returned empty status and findings.")
        try:
            train_outputs = _parse_generator_outputs(
                data.train_outputs,
                fallback=state.train_partial_outputs,
            )
        except Exception as exc:
            state.logs.append(
                f"Error parsing generator train outputs: {exc}. Using previous partial outputs."
            )
            train_outputs = state.train_partial_outputs
        try:
            test_outputs = _parse_generator_outputs(
                data.test_outputs,
                fallback=state.test_partial_outputs,
            )
        except Exception as exc:
            state.logs.append(
                f"Error parsing generator test outputs: {exc}. Using previous partial outputs."
            )
            test_outputs = state.test_partial_outputs
        return GeneratorAgentResult(
            status_and_findings=status_and_findings,
            train_outputs=train_outputs,
            test_outputs=test_outputs,
            usage=usage,
        )

    def _build_input(
        self, state: SolverState, instruction: str
    ) -> list[dict[str, Any]]:
        parts: list[dict[str, Any]] = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "input_text",
                        "text": self.system_prompt
                        + f"\nPrevious status and findings:\n{state.generator_status_and_findings or 'N/A'}.\nEnsure your new status and findings message combines with and builds upon this previous one.",
                    }
                ],
            }
        ]
        user_parts: list[dict[str, Any]] = [
            {
                "type": "input_text",
                "text": (
                    f"Task ID: {state.task_id}\n"
                    f"Step index: {state.step_index}\n"
                    f"New instruction: {instruction}"
                ),
            }
        ]
        if state.instructions:
            history = "\n".join(
                f"{idx + 1}. {inst}" for idx, inst in enumerate(state.instructions)
            )
            user_parts.append({"type": "input_text", "text": "Instruction history:"})
            user_parts.append({"type": "input_text", "text": history})

        train_entries = []
        for index, grid in enumerate(state.samples.train_inputs):
            train_entries.append({"label": f"Train {index} INPUT", "grid": grid})
            partial = state.train_partial_outputs[index]
            if partial is not None:
                train_entries.append(
                    {
                        "label": f"Train {index} CURRENT OUTPUT",
                        "grid": partial,
                        "text": grid_to_text(partial),
                    }
                )

        test_entries = []
        for index, grid in enumerate(state.samples.test_inputs):
            test_entries.append({"label": f"Test {index} INPUT", "grid": grid})
            partial = state.test_partial_outputs[index]
            if partial is not None:
                test_entries.append(
                    {
                        "label": f"Test {index} CURRENT OUTPUT",
                        "grid": partial,
                        "text": grid_to_text(partial),
                    }
                )

        if train_entries:
            user_parts.extend(
                build_user_content_samples(
                    "Train Sample",
                    train_entries,
                    use_images=state.config.should_use_images(),
                )
            )
        if test_entries:
            user_parts.extend(
                build_user_content_samples(
                    "Test Sample",
                    test_entries,
                    use_images=state.config.should_use_images(),
                )
            )

        parts.append({"role": "user", "content": user_parts})
        return parts


class InstructionSchema(BaseModel):
    instruction: str
    rationale: str
    confidence: InstructionConfidence


class GeneratorSchema(BaseModel):
    status_and_findings: str
    train_outputs: list[GeneratorGridResult]
    test_outputs: list[GeneratorGridResult]


def _extract_usage(response: Any) -> dict[str, int]:
    usage = getattr(response, "usage", None)
    if usage is None:
        return {}
    return {
        "input_tokens": int(getattr(usage, "input_tokens", 0)),
        "cached_tokens": int(
            getattr(getattr(usage, "input_tokens", {}), "cached_tokens", 0)
        ),
        "output_tokens": int(getattr(usage, "output_tokens", 0)),
        "total_tokens": int(getattr(usage, "total_tokens", 0)),
    }


def _parse_generator_outputs(
    items: Sequence[GeneratorGridResult],
    *,
    fallback: Sequence[GRID | None],
) -> list[GeneratorGridResult]:
    results: list[GeneratorGridResult] = []
    for index, item in enumerate(items):
        grid = item.grid
        text = item.grid_text
        image_b64 = item.grid_image_b64
        if grid is None:
            grid = fallback[index] if index < len(fallback) else None
        if grid is not None and text is None:
            text = grid_to_text(grid)
        if grid is not None and image_b64 is None:
            image_b64 = grid_to_base64_png(grid)
        results.append(
            GeneratorGridResult(
                grid=grid,
                grid_text=text,
                grid_image_b64=image_b64,
            )
        )
    return results
