from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Literal, Sequence, Optional

from openai import OpenAI
from pydantic import BaseModel

from representation_utils import (
    GRID,
    generate_grid_diff,
    grid_to_base64_png,
    grid_to_text,
)
from state import SolverState, build_user_content_samples

InstructionConfidence = Literal["low", "medium", "high"]


@dataclass(slots=True)
class InstructionAgentResult:
    instruction: str
    status: str
    # rationale: str
    # confidence: InstructionConfidence
    usage: dict[str, int]


@dataclass(slots=True)
class GeneratorGridResult:
    grid: GRID | None
    grid_text: str | None
    grid_image_b64: str | None


@dataclass(slots=True)
class GeneratorAgentResult:
    status_and_findings: str
    train_outputs: list[GeneratorGridResult]
    test_outputs: list[GeneratorGridResult]
    usage: dict[str, int]


INSTRUCTION_AGENT_SYSTEM_PROMPT = """
You are an expert ARC reasoning assistant.
You are given the current state of an ARC puzzle solving attempt, including:
- Train and test samples with inputs, train expected outputs, and any current partial outputs generated by the generator agent.
- For train samples, diffs between expected outputs and current partial outputs, if any. Test samples do not have expected outputs and thus also no diffs.
- The history of instructions issued so far.
- The status and findings reported by the generator agent for the instructions including the latest one.
Your task is to think about the transformation and identify the entire sequence of transformation. Then, as your response, produce one minimal, precise next instruction step for the generator agent to apply.
These instruction steps must:

- Be based on your thinking process about the transformation pattern observed in the training samples.
- Be incremental, building upon previous instructions.
- Focus on a single, clear transformation action or identification step.
- Be actionable by the generator agent to update the outputs.
- Max number of generator steps allowed is {max_steps} including any potential corrective instructions you may give, so plan accordingly.
- Reflect your confidence level in the instruction you are providing (low, medium, high).
- Apply consistently to ALL training examples (the same rule works for every input→output pair)
- Be intuitive and easy to understand
- Be as specific as possible to avoid ambiguity

The eventual goal is to solve the test samples correctly by iteratively applying these instructions. It is acceptable that the instructions have specific details tailored to the test samples.
If the generator agent doesn't seem to be on the correct path, provide corrective instructions.
Ensure to check test samples as well for consistency. If the test samples reveal issues not apparent in the training samples, adjust your instructions accordingly. You may give instructions that specifically address the test samples if needed.

A few examples of good instructions:
example 1:
- Identify the largest connected component in the input grid
- Recolor it to color 3, and mirror it horizontally.
example 2:
- Crop the input grid to the bounding box of non-background pixels, 
- then rotate it 90 degrees clockwise and place it in the top-left corner of the output grid.
example 3:
- Identify all objects in the input grid. Ignore the bracket objects that are size ... and shape .... 
- For the remaining objects, recolor them to color ... and translate them according to this rule: ...
example 4:
- Identify the smaller area created by a color 5 border. This is the guide area.
- Inside this area, color mappings are given as a guide. Objects with 1 hole in it are colored with a certain color, objects with 2 holes another color, etc. Identify these mappings.
- The objects in the larger area are then recolored according to the mapping.

The actual instructions you write must follow the same principles as these examples, but be tailored to the specific transformation pattern in the training data provided.

Never execute the transformation yourself.
Reference previous instructions, generator status and findings, and diffs between expected and actual outputs.
Allow revisions to previous instructions when necessary.

"""

INSTRUCTION_AGENT_SYSTEM_PROMPT_TRAIN_INPUTS = """
You are an expert ARC reasoning assistant.
You are given the current state of an ARC puzzle solving attempt, including:
- Train samples with inputs, train expected outputs, and (if any) current train outputs generated by the generator agent.
- The history of instructions issued so far.
- The status and findings reported by the generator agent for the instructions given so far.

Initially, there won't be any generated outputs, or status and findings. You will think about the transformation and then produce full instructions. But as the solving attempt progresses, there will be previous attempts and statuses available for your consideration.

Your task is to think about the transformation and identify the entire sequence of transformation. Then, as your response:
- If this is initial instruction (no previous instructions and no previous generated outputs), produce a full set of instructions that, when applied sequentially, will solve all training samples correctly.
- If current train outputs and their diffs are given, produce a new set of instructions addressing any gaps or errors observed so far.
Status: always output in progress.

These instruction steps must:
- Be based on your thinking process about the transformation pattern observed in the training samples.
- Involve single, clear transformation actions or identification steps.
- Apply consistently to ALL training examples (the same rule works for every input→output pair) and the test samples.
- Be intuitive and easy to understand
- Be as specific as possible to avoid ambiguity

A few examples of good instructions:
example 1:
- Identify the largest connected component in the input grid
- Recolor it to color 3, and mirror it horizontally.
example 2:
- Crop the input grid to the bounding box of non-background pixels, 
- then rotate it 90 degrees clockwise and place it in the top-left corner of the output grid.
example 3:
- Identify all objects in the input grid. Ignore the bracket objects that are size ... and shape .... 
- For the remaining objects, recolor them to color ... and translate them according to this rule: ...
example 4:
- Identify the smaller area created by a color 5 border. This is the guide area.
- Inside this area, color mappings are given as a guide. Objects with 1 hole in it are colored with a certain color, objects with 2 holes another color, etc. Identify these mappings.
- The objects in the larger area are then recolored according to the mapping.

The actual instructions you write must follow the same principles as these examples, but be tailored to the specific transformation pattern in the training data provided.

Never execute the transformation yourself.
Reference previous instructions, generator status and findings, and current outputs.
Allow revisions to previous instructions when necessary.
"""

INSTRUCTION_AGENT_SYSTEM_PROMPT_TEST_INPUTS = """
You are an expert ARC reasoning assistant. You have already processed the training samples and issued instructions accordingly. The generator agent has applied those instructions to training samples and their outputs have been verified.
You are now going to help solve the test samples. You are given the current state of the ARC puzzle solving attempt, including:
- Train samples with inputs, train expected outputs, and (if any) current test outputs generated by the generator agent.
- The history of instructions issued so far.
- The status and findings reported by the generator agent for the instructions given so far.

Your task is to think about the transformation and identify the entire sequence of transformation. You are given the full history of instructions you have issued so far, which helped solve the training samples correctly.
Now, your job is to generate instructions to help the generator agent apply those learned transformations to the test samples. Given the history of instructions (which may include corrective steps), generate the new set of instructions to apply to the test samples.

- If current test output is given and you are satisfied that it has the same transformation pattern as the training samples, and it applies the instructions correctly, then output status: "complete". Otherwise (or no current test output), output status: "in progress".
- In case of in progress status, produce instructions for the generator agent to apply. If current test outputs are given, you should consider them as your previous outputs. Instructions may refer to previous outputs in corrective or refining steps, or they may instruct to throw away previous outputs and start anew.
Previous test output is given for context after the initial attempt.

The eventual goal is to solve the test samples correctly by iteratively applying these instructions. It is acceptable that the instructions have specific details tailored to the test samples.
If the generator agent doesn't seem to be on the correct path, provide corrective instructions.
Ensure to check test samples for correctness. If the test samples reveal issues, adjust your instructions accordingly. You may give instructions that specifically address the test samples if needed.
"""

GENERATOR_AGENT_SYSTEM_PROMPT = """
You transform ARC grids strictly following the provided instructions.
Update outputs for all train and test samples.
You must always output updated grids. If the instruction does not require any changes yet, you must still output the existing grids (input grids or the latest grids) unchanged.
Always re-emit existing outputs unchanged when no update is required.
Your previous status and findings message is below. Return a new, complete status and findings message that combines the previous one with your latest observations and status.
For example, if an instruction says "Identify the largest connected component" then your status and findings should describe precisely what you found regarding connected components in the inputs.
For example, if an instruction says "Recolor all objects of color 3 to color 5", your status and findings should describe how many objects of color 3 you found and recolored in each sample. You must also update the output grids accordingly.
"""

GENERATOR_AGENT_SYSTEM_PROMPT_V2 = """
You transform ARC grids strictly following the provided instructions.
You are given {type} samples to process, as well as your previous transformation outputs and status and findings (if any).
Instructions are provided. If current {type} outputs are given, you should consider them as your previous outputs. Instructions may refer to previous outputs in corrective or refining steps.
Apply all the instructions given to you, in order, to the given inputs, in order to generate or update your outputs.
You must always produce new full output grids for all {type} samples. If you are given train samples, you must produce outputs for all train samples. If you are given test samples, you must produce outputs for all test samples.
Your previous status and findings message is below. Return a new, complete status and findings message that combines the previous one with your latest observations and status.
For example, if an instruction says "Identify the largest connected component" then your status and findings should describe precisely what you found regarding connected components in the inputs.
For example, if an instruction says "Recolor all objects of color 3 to color 5", your status and findings should describe how many objects of color 3 you found and recolored in each sample. You must also update the output grids accordingly.
"""


class InstructionAgent:
    """LLM-backed instruction planner producing single incremental steps."""

    def __init__(self, client: OpenAI, *, system_prompt: str | None = None) -> None:
        self.client = client
        self.system_prompt = system_prompt or INSTRUCTION_AGENT_SYSTEM_PROMPT

    def __call__(self, state: SolverState) -> InstructionAgentResult:
        if state.graph_status == "running train":
            self.system_prompt = INSTRUCTION_AGENT_SYSTEM_PROMPT_TRAIN_INPUTS
        else:
            self.system_prompt = INSTRUCTION_AGENT_SYSTEM_PROMPT_TEST_INPUTS
        input_payload = self._build_input(state)
        response = self.client.responses.parse(
            model="gpt-5",
            input=input_payload,
            reasoning={"effort": state.config.reasoning_effort()},
            service_tier="priority",
            text_format=InstructionSchema,
        )
        data = response.output_parsed
        usage = _extract_usage(response)
        instruction = data.instruction.strip()
        status = data.status.strip()
        # rationale = data.rationale.strip()
        # confidence = data.confidence.strip() or "medium"
        if not instruction:
            raise ValueError("Instruction agent returned empty instruction.")
        return InstructionAgentResult(
            instruction=instruction,
            status=status,
            # rationale=rationale,
            # confidence=confidence,  # type: ignore[arg-type]
            usage=usage,
        )

    def _build_input(self, state: SolverState) -> list[dict[str, Any]]:
        parts: list[dict[str, Any]] = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "input_text",
                        "text": self.system_prompt,
                        # .format(
                        #     max_steps=state.config.max_steps,
                        # ),
                    }
                ],
            }
        ]
        user_parts: list[dict[str, Any]] = []

        if state.instructions:
            instruction_lines = "\n".join(
                f"{idx + 1}. {text}" for idx, text in enumerate(state.instructions)
            )
            user_parts.append({"type": "input_text", "text": "Instructions so far:"})
            user_parts.append({"type": "input_text", "text": instruction_lines})
        else:
            user_parts.append(
                {"type": "input_text", "text": "Instructions so far: (none)"}
            )
        user_parts.append(
            {
                "type": "input_text",
                "text": f"Generator status and findings so far: {state.generator_status_and_findings or 'N/A'}",
            }
        )
        train_entries = []
        for index, (train_input, train_expected) in enumerate(
            zip(state.samples.train_inputs, state.samples.train_outputs, strict=True)
        ):
            train_entries.append(
                {
                    "label": f"Train {index} INPUT",
                    "grid": train_input,
                }
            )
            if state.graph_status == "running train":
                diff_text = None
                partial = state.train_partial_outputs[index]
                if partial is not None:
                    diff_text = generate_grid_diff(train_expected, partial)
                if partial is not None:
                    train_entries.append(
                        {
                            "label": f"Train {index} CURRENT PROGRESS OUTPUT FROM GENERATOR",
                            "grid": partial,
                            "diff": diff_text,
                        }
                    )
            train_entries.append(
                {
                    "label": f"Train {index} EXPECTED OUTPUT",
                    "grid": train_expected,
                }
            )

        test_entries = []
        if state.graph_status == "running test":
            for index, test_input in enumerate(state.samples.test_inputs):
                partial = state.test_partial_outputs[index]
                test_entries.append(
                    {
                        "label": f"Test {index} INPUT",
                        "grid": test_input,
                    }
                )
                if partial is not None:
                    test_entries.append(
                        {
                            "label": f"Test {index} CURRENT PROGRESS OUTPUT FROM GENERATOR",
                            "grid": partial,
                        }
                    )

        if train_entries:
            user_parts.extend(
                build_user_content_samples(
                    "Train Sample",
                    train_entries,
                    use_images=state.config.should_use_images(),
                )
            )
        if test_entries:
            user_parts.extend(
                build_user_content_samples(
                    "Test Sample",
                    test_entries,
                    use_images=state.config.should_use_images(),
                )
            )

        parts.append({"role": "user", "content": user_parts})
        return parts


class GeneratorAgent:
    """LLM-backed agent applying instructions to produce partial outputs."""

    def __init__(self, client: OpenAI, *, system_prompt: str | None = None) -> None:
        self.client = client
        self.system_prompt = system_prompt or GENERATOR_AGENT_SYSTEM_PROMPT_V2

    def __call__(self, state: SolverState, instruction: str) -> GeneratorAgentResult:
        if state.graph_status == "running train":
            self.system_prompt = GENERATOR_AGENT_SYSTEM_PROMPT_V2.format(type="train")
        else:
            self.system_prompt = GENERATOR_AGENT_SYSTEM_PROMPT_V2.format(type="test")
        input_payload = self._build_input(state, instruction)
        response = self.client.responses.parse(
            model="gpt-5",
            input=input_payload,
            reasoning={"effort": state.config.reasoning_effort()},
            service_tier="priority",
            text_format=GeneratorSchema,
            # (
            #     GeneratorSchemaTrain
            #     if state.graph_status == "running train"
            #     else GeneratorSchemaTest
            # ),
        )
        data = response.output_parsed
        usage = _extract_usage(response)
        status_and_findings = data.status_and_findings.strip()
        if not status_and_findings:
            raise ValueError("Generator agent returned empty status and findings.")
        train_outputs = []
        test_outputs = []
        if state.graph_status == "running train":
            try:
                train_outputs = _parse_generator_outputs(
                    data.train_outputs,
                    fallback=state.train_partial_outputs,
                )
            except Exception as exc:
                state.logs.append(
                    f"Error parsing generator train outputs: {exc}. Using previous partial outputs."
                )
                train_outputs = state.train_partial_outputs
        if state.graph_status == "running test":
            try:
                test_outputs = _parse_generator_outputs(
                    data.test_outputs,
                    fallback=state.test_partial_outputs,
                )
            except Exception as exc:
                state.logs.append(
                    f"Error parsing generator test outputs: {exc}. Using previous partial outputs."
                )
                test_outputs = state.test_partial_outputs
        return GeneratorAgentResult(
            status_and_findings=status_and_findings,
            train_outputs=train_outputs,
            test_outputs=test_outputs,
            usage=usage,
        )

    def _build_input(
        self, state: SolverState, instruction: str
    ) -> list[dict[str, Any]]:
        parts: list[dict[str, Any]] = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "input_text",
                        "text": self.system_prompt
                        + f"\nPrevious status and findings:\n{state.generator_status_and_findings or 'N/A'}.\nEnsure your new status and findings message combines with and builds upon this previous one.",
                    }
                ],
            }
        ]
        user_parts: list[dict[str, Any]] = [
            {
                "type": "input_text",
                "text": (
                    f"Task ID: {state.task_id}\n"
                    f"Step index: {state.step_index}\n"
                    f"New instruction: {instruction}"
                ),
            }
        ]
        # if state.instructions:
        #     history = "\n".join(
        #         f"{idx + 1}. {inst}" for idx, inst in enumerate(state.instructions)
        #     )
        #     user_parts.append({"type": "input_text", "text": "Instruction history:"})
        #     user_parts.append({"type": "input_text", "text": history})

        train_entries = []
        if state.graph_status == "running train":
            for index, grid in enumerate(state.samples.train_inputs):
                train_entries.append({"label": f"Train {index} INPUT", "grid": grid})
                partial = state.train_partial_outputs[index]
                if partial is not None:
                    train_entries.append(
                        {
                            "label": f"Train {index} CURRENT PROGRESS OUTPUT",
                            "grid": partial,
                            "text": grid_to_text(partial),
                        }
                    )

        test_entries = []
        if state.graph_status == "running test":
            for index, grid in enumerate(state.samples.test_inputs):
                test_entries.append({"label": f"Test {index} INPUT", "grid": grid})
                partial = state.test_partial_outputs[index]
                if partial is not None:
                    test_entries.append(
                        {
                            "label": f"Test {index} CURRENT PROGRESS OUTPUT",
                            "grid": partial,
                            "text": grid_to_text(partial),
                        }
                    )

        if train_entries:
            user_parts.extend(
                build_user_content_samples(
                    "Train Sample",
                    train_entries,
                    use_images=state.config.should_use_images(),
                )
            )
        if test_entries:
            user_parts.extend(
                build_user_content_samples(
                    "Test Sample",
                    test_entries,
                    use_images=state.config.should_use_images(),
                )
            )

        parts.append({"role": "user", "content": user_parts})
        return parts


class InstructionSchema(BaseModel):
    instruction: str
    status: str
    # rationale: str
    # confidence: InstructionConfidence


class GeneratorSchema(BaseModel):
    status_and_findings: str
    train_outputs: Optional[list[GRID]]
    test_outputs: Optional[list[GRID]]


def _extract_usage(response: Any) -> dict[str, int]:
    usage = getattr(response, "usage", None)
    if usage is None:
        return {}
    return {
        "input_tokens": int(getattr(usage, "input_tokens", 0)),
        "cached_tokens": int(
            getattr(getattr(usage, "input_tokens", {}), "cached_tokens", 0)
        ),
        "output_tokens": int(getattr(usage, "output_tokens", 0)),
        "total_tokens": int(getattr(usage, "total_tokens", 0)),
    }


def _parse_generator_outputs(
    items: Sequence[GRID],
    *,
    fallback: Sequence[GRID],
) -> list[GeneratorGridResult]:
    results: list[GeneratorGridResult] = []
    for index, grid in enumerate(items):
        if grid is None:
            grid = fallback[index] if index < len(fallback) else None
        text = grid_to_text(grid)
        image_b64 = grid_to_base64_png(grid)
        results.append(
            GeneratorGridResult(
                grid=grid,
                grid_text=text,
                grid_image_b64=image_b64,
            )
        )
    return results
